{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "858a5735-8db4-4be9-be5b-a0d3e6cbfab7",
   "metadata": {
    "id": "858a5735-8db4-4be9-be5b-a0d3e6cbfab7"
   },
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7eec7180-b53a-44be-a57f-13840fe87b21",
   "metadata": {
    "id": "7eec7180-b53a-44be-a57f-13840fe87b21"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import re\n",
    "import helper\n",
    "import random\n",
    "import string\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import pdb\n",
    "\n",
    "import time\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "87fa110a-640b-42ac-8a7d-806d251e4952",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "87fa110a-640b-42ac-8a7d-806d251e4952",
    "outputId": "6c5f22d0-6797-47e1-95c5-817663acd2e5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'helper' from '/Users/glchau/Desktop/Caltech/CS155/loan-sharks/poems/helper.py'>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run this to reload helper.py so you don't have to restart the kernel\n",
    "import importlib\n",
    "\n",
    "importlib.reload(helper)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bace0ca-0c69-4877-ba48-cc5342abd20d",
   "metadata": {
    "id": "7bace0ca-0c69-4877-ba48-cc5342abd20d"
   },
   "source": [
    "## Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea55bd15-6a4b-4a6c-b20c-f09f63acda0b",
   "metadata": {
    "id": "ea55bd15-6a4b-4a6c-b20c-f09f63acda0b"
   },
   "outputs": [],
   "source": [
    "all_words, all_sequences, word_dict, all_sonnet_int = helper.getAllWordsAndSequences(\"data/shakespeare.txt\", \"data/Syllable_dictionary.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bad57e2b-ffe2-469e-8b78-fbe87687a3e4",
   "metadata": {
    "id": "bad57e2b-ffe2-469e-8b78-fbe87687a3e4"
   },
   "source": [
    "## Variables and helper functions for RNN training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a9b8403d-f8c5-4a2a-94ed-b51fa187a16d",
   "metadata": {
    "id": "a9b8403d-f8c5-4a2a-94ed-b51fa187a16d"
   },
   "outputs": [],
   "source": [
    "all_character_sequences = [' '.join(seq[:-1]) for seq in all_sequences]\n",
    "all_character_sequences_no_empty = [seq for seq in all_character_sequences if len(seq) > 0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a793b073-1909-4945-aa82-534f35343e1b",
   "metadata": {
    "id": "a793b073-1909-4945-aa82-534f35343e1b"
   },
   "outputs": [],
   "source": [
    "fixed_length_character_sequences_valid_start = [] \n",
    "big_string = ' '.join(all_character_sequences_no_empty)\n",
    "big_string = ' ' + big_string\n",
    "step_size = 5\n",
    "for i in range(0, len(big_string)):\n",
    "    if (big_string[i-1] == ' ') and (big_string[i] != ' '):\n",
    "        if len(big_string[i:i+40]) == 40: \n",
    "            fixed_length_character_sequences_valid_start.append(big_string[i:i+40])        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dIjkH1vllj3E",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dIjkH1vllj3E",
    "outputId": "03982446-9069-4ba5-a908-1c90dbf299cf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17566"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(fixed_length_character_sequences_valid_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "debd5e9a-ff3c-48a8-93da-1571cced25e0",
   "metadata": {
    "id": "debd5e9a-ff3c-48a8-93da-1571cced25e0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_letters = string.ascii_lowercase + \" '-\"  # abcdefghijklmnopqrstuvwxyz '-\n",
    "n_letters = len(all_letters) + 1 # Plus EOS marker\n",
    "all_categories = [0] # Only have 1 category for now. We could try to categorize lines by position or ending rhyme\n",
    "n_categories = len(all_categories)\n",
    "\n",
    "lens = [len(seq) for seq in fixed_length_character_sequences_valid_start]\n",
    "max_length = max(lens)\n",
    "min_lenth = min(lens)\n",
    "max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a0830690-3e2d-4a92-87a0-d03d2c631fee",
   "metadata": {
    "id": "a0830690-3e2d-4a92-87a0-d03d2c631fee"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3a2e1100-9420-4f4c-b46c-e7a269fc1796",
   "metadata": {
    "id": "3a2e1100-9420-4f4c-b46c-e7a269fc1796"
   },
   "outputs": [],
   "source": [
    "def inputTensor(line):\n",
    "    # One-hot matrix of first to last letters (not including EOS) for input\n",
    "    # tensor = torch.zeros(len(line), n_letters)\n",
    "    # for li in range(len(line)):\n",
    "    #     letter = line[li]\n",
    "    #     tensor[li][all_letters.find(letter)] = 1\n",
    "    \n",
    "    # Indices \n",
    "    letter_indexes = [all_letters.find(line[li]) for li in range(0, len(line))]\n",
    "    return torch.LongTensor(letter_indexes) #tensor\n",
    "\n",
    "# LongTensor of second letter to end (EOS) for target\n",
    "def targetTensor(line):\n",
    "    letter_indexes = [all_letters.find(line[li]) for li in range(1, len(line))]\n",
    "    letter_indexes.append(n_letters - 1) # EOS\n",
    "    return torch.LongTensor(letter_indexes)\n",
    "\n",
    "def inputTargetLists(line): \n",
    "    inputList = [all_letters.find(line[li]) for li in range(0, len(line))]\n",
    "    targetList = [all_letters.find(line[li]) for li in range(1, len(line))]\n",
    "    targetList.append(n_letters - 1)\n",
    "    return inputList, targetList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8d0738f2-f47d-41a0-8777-ccda74863a42",
   "metadata": {
    "id": "8d0738f2-f47d-41a0-8777-ccda74863a42"
   },
   "outputs": [],
   "source": [
    "# Random item from a list\n",
    "def randomChoice(l):\n",
    "    return l[random.randint(0, len(l) - 1)]\n",
    "\n",
    "# Generate a batch of lines with input and target tensors \n",
    "def randomBatch(category_lines, batch_size=16):\n",
    "    input_tensors = []\n",
    "    target_tensors = []\n",
    "    for b in range(batch_size): \n",
    "        line = randomChoice(category_lines)\n",
    "        inputList, targetList = inputTargetLists(line)\n",
    "        \n",
    "        input_tensors.append(inputList)\n",
    "        target_tensors.append(targetList)\n",
    "    return torch.LongTensor(input_tensors), torch.LongTensor(target_tensors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "309c8d4b-b6f3-48fe-a577-9717ebffc1af",
   "metadata": {
    "id": "309c8d4b-b6f3-48fe-a577-9717ebffc1af"
   },
   "source": [
    "### Training Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "445fc3a6-2055-4e5b-bf25-3aa28718d306",
   "metadata": {
    "id": "445fc3a6-2055-4e5b-bf25-3aa28718d306"
   },
   "outputs": [],
   "source": [
    "def timeSince(since):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3d5498fa-d334-4afe-8261-4dddef793cd7",
   "metadata": {
    "id": "3d5498fa-d334-4afe-8261-4dddef793cd7"
   },
   "outputs": [],
   "source": [
    "# train the RNN on the input and target batch values \n",
    "\n",
    "def train_batch(rnn, input_line_tensor, target_line_tensor, optimizer, criterion):\n",
    "    \n",
    "    # Put in extra dimension for the \"Layer\" dimension of LSTM inputs \n",
    "    input_line_tensor = torch.unsqueeze(input_line_tensor, dim=0)\n",
    "    target_line_tensor = torch.unsqueeze(target_line_tensor, dim=0)\n",
    "    \n",
    "    # Initilize the hidden and cell matrices \n",
    "    hidden, cell = rnn.initHidden()\n",
    "\n",
    "    # Zero out the gradients for each batch\n",
    "    rnn.zero_grad()\n",
    "\n",
    "    # Initlize loss to 0\n",
    "    loss = 0\n",
    "\n",
    "    # Iterate through all 40 characters in the sequence\n",
    "    for i in range(input_line_tensor.size(2)):\n",
    "        \n",
    "        # Select only the ith character for the batch\n",
    "        input_tensor = input_line_tensor[:, :, i] \n",
    "        target_tensor = target_line_tensor[:, :, i] \n",
    "        \n",
    "        # Forward pass through RNN \n",
    "        output, (hidden, cell) = rnn(input_tensor, (hidden, cell))\n",
    "        \n",
    "        # Loss calculation\n",
    "        l = criterion(torch.squeeze(output, dim=0), torch.squeeze(target_tensor, dim=0))\n",
    "        loss += l.item() \n",
    "\n",
    "        # Compute gradients and take optimizer step\n",
    "        optimizer.zero_grad()\n",
    "        l.backward(retain_graph=True)\n",
    "        optimizer.step()\n",
    "\n",
    "    return loss / rnn.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e9891d34-227d-4305-9036-f09e30fe05ae",
   "metadata": {
    "id": "e9891d34-227d-4305-9036-f09e30fe05ae"
   },
   "outputs": [],
   "source": [
    "# Sample from a category and starting letter\n",
    "\n",
    "def sample(rnn, start_letter='a', length=max_length, temperature=1):\n",
    "    with torch.no_grad():  # no need to track history in sampling\n",
    "        rnn.eval()\n",
    "        inputs = inputTensor(start_letter).to(device)\n",
    "        hidden, cell = torch.zeros(1, 1, rnn.hidden_size).to(device), torch.zeros(1, 1, rnn.hidden_size).to(device)\n",
    "\n",
    "        output_name = start_letter\n",
    "\n",
    "        for i in range(length):\n",
    "            inputs = inputs[None, :]\n",
    "            \n",
    "            output, (hidden, cell) = rnn(inputs, (hidden, cell), temperature=temperature)\n",
    "            \n",
    "            topi = torch.multinomial(output.data[0], 1)\n",
    "            # pdb.set_trace()\n",
    "            # topv, topi = output.topk(1)\n",
    "            topi = topi[0][0]\n",
    "            \n",
    "            # Last index is <EOS> so we just kill the appending\n",
    "            if topi == n_letters - 1:\n",
    "                break \n",
    "            else:\n",
    "                letter = all_letters[topi]\n",
    "                output_name += letter\n",
    "            \n",
    "            inputs = inputTensor(letter).to(device)\n",
    "\n",
    "        return output_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "554a28f4-2e9b-499e-a62e-63447290409c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample from a category and starting letter\n",
    "\n",
    "def sampleMultipleStart(rnn, start_seq='ant', length=max_length, temperature=1):\n",
    "    with torch.no_grad():  # no need to track history in sampling\n",
    "        rnn.eval()\n",
    "        \n",
    "        \n",
    "        hidden, cell = torch.zeros(1, 1, rnn.hidden_size).to(device), torch.zeros(1, 1, rnn.hidden_size).to(device)\n",
    "\n",
    "        input_array = []\n",
    "        for char in start_seq: \n",
    "            input_array.append(inputTensor(char).to(device))\n",
    "        output_sequence = start_seq\n",
    "        \n",
    "        for i in range(len(start_seq) - 1): \n",
    "            inputs = input_array[i][None, :].to(device)\n",
    "            output, (hidden, cell) = rnn(inputs, (hidden, cell), temperature=temperature)\n",
    "\n",
    "        inputs = input_array[len(start_seq) - 1][None, :]\n",
    "        for i in range(length):\n",
    "            \n",
    "            output, (hidden, cell) = rnn(inputs, (hidden, cell), temperature=temperature)\n",
    "            # output = output.data[0] / sum(output.data[0][0]) \n",
    "            topi = torch.multinomial(output.data[0], 1)\n",
    "            \n",
    "            # topv, topi = output.topk(1)\n",
    "            topi = topi[0][0]\n",
    "            \n",
    "            # Last index is <EOS> so we just kill the appending\n",
    "            if topi == n_letters - 1:\n",
    "                break \n",
    "            else:\n",
    "                letter = all_letters[topi]\n",
    "                output_sequence += letter\n",
    "            \n",
    "            inputs = inputTensor(letter)[None, :].to(device)\n",
    "\n",
    "        return output_sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08ncG8mBk96R",
   "metadata": {
    "id": "08ncG8mBk96R"
   },
   "source": [
    "## One Hot encoding LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bb404074-20ea-4a9f-859e-14675bec362e",
   "metadata": {
    "id": "bb404074-20ea-4a9f-859e-14675bec362e"
   },
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, n_classes, batch_size, device, n_layers=1): # n_classes is output_size \n",
    "        super(RNN, self).__init__()\n",
    "        self.input_size = input_size # input size is number of classes in our case \n",
    "        self.hidden_size = hidden_size # hidden layer size \n",
    "        self.n_classes = n_classes # number of classes \n",
    "        self.batch_size = batch_size # size of batch\n",
    "        self.n_layers = n_layers # number of layers in LSTM\n",
    "        self.device = device # 'cuda' or 'cpu'\n",
    "        \n",
    "\n",
    "        # self.embedding = nn.Embedding(input_size, input_size)\n",
    "        self.lstm = nn.LSTM(input_size=input_size, hidden_size=hidden_size, num_layers=1)\n",
    "        self.decoder = nn.Linear(hidden_size, n_classes)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.softmax = nn.Softmax(dim=2)\n",
    "        \n",
    "\n",
    "    def forward(self, input_vals, hc, temperature=1):\n",
    "        # embeding = self.embedding(input_vals)\n",
    "        one_hot = torch.nn.functional.one_hot(input_vals, num_classes=self.n_classes)\n",
    "        # pdb.set_trace()\n",
    "        output, hc = self.lstm(one_hot.float(), hc)\n",
    "        output = self.decoder(output)\n",
    "        output = self.dropout(output)\n",
    "        # pdb.set_trace()\n",
    "        output = self.softmax(output / temperature)\n",
    "        return output, (hc[0].detach(), hc[1].detach())\n",
    "\n",
    "    def initHidden(self, num_layers=None, batch_size=None, hidden_size=None):\n",
    "        if num_layers is None:\n",
    "            num_layers = self.n_layers\n",
    "        if batch_size is None:\n",
    "            batch_size = self.batch_size\n",
    "        if hidden_size is None:\n",
    "            hidden_size = self.hidden_size\n",
    "            \n",
    "        return torch.zeros(num_layers, batch_size, hidden_size).to(self.device), torch.zeros(num_layers, batch_size, hidden_size).to(self.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "46a31cc0-8346-4d34-a866-a94666eb60ba",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "46a31cc0-8346-4d34-a866-a94666eb60ba",
    "outputId": "e0aba8e1-8a10-4e5a-eb65-5248751033ae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1m 5s (500 3%) 3.8773\n",
      "2m 9s (1000 6%) 3.8244\n",
      "3m 13s (1500 10%) 3.8316\n",
      "4m 16s (2000 13%) 3.8275\n",
      "5m 20s (2500 16%) 3.8084\n",
      "6m 23s (3000 20%) 3.8150\n",
      "7m 27s (3500 23%) 3.7547\n",
      "8m 30s (4000 26%) 3.7767\n",
      "9m 33s (4500 30%) 3.7528\n",
      "10m 37s (5000 33%) 3.7539\n",
      "11m 40s (5500 36%) 3.7679\n",
      "12m 44s (6000 40%) 3.7235\n",
      "13m 47s (6500 43%) 3.7552\n",
      "14m 51s (7000 46%) 3.7511\n",
      "15m 54s (7500 50%) 3.7514\n",
      "16m 58s (8000 53%) 3.7571\n",
      "18m 1s (8500 56%) 3.7092\n",
      "19m 5s (9000 60%) 3.7318\n",
      "20m 9s (9500 63%) 3.7266\n",
      "21m 12s (10000 66%) 3.7419\n",
      "22m 16s (10500 70%) 3.7102\n",
      "23m 20s (11000 73%) 3.7427\n",
      "24m 24s (11500 76%) 3.7430\n",
      "25m 27s (12000 80%) 3.7469\n",
      "26m 31s (12500 83%) 3.7269\n",
      "27m 35s (13000 86%) 3.7187\n",
      "28m 39s (13500 90%) 3.7206\n",
      "29m 43s (14000 93%) 3.7067\n",
      "30m 47s (14500 96%) 3.7366\n",
      "31m 52s (15000 100%) 3.7079\n"
     ]
    }
   ],
   "source": [
    "######### PARAMETERS #########\n",
    "batch_size = 32\n",
    "hidden_size = 256\n",
    "n_iters = 15000\n",
    "print_every = 500\n",
    "plot_every = 500\n",
    "learning_rate = 0.0005\n",
    "############################## \n",
    "\n",
    "rnn = RNN(n_letters, hidden_size, n_letters, device=device, batch_size=batch_size).to(device) # expand hidden units \n",
    "\n",
    "criterion = nn.CrossEntropyLoss() \n",
    "\n",
    "optimizer = torch.optim.Adam(rnn.parameters(), lr=learning_rate)\n",
    "\n",
    "all_losses = []\n",
    "total_loss = 0 # Reset every plot_every iters\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "for iter in range(1, n_iters + 1):\n",
    "    try : \n",
    "        input_line_tensor, target_line_tensor = randomBatch(fixed_length_character_sequences_valid_start, batch_size=batch_size)\n",
    "        loss = train_batch(rnn, input_line_tensor.to(device), target_line_tensor.to(device), criterion=criterion, optimizer=optimizer)\n",
    "        total_loss += loss\n",
    "    except : \n",
    "        print(input_line_tensor)\n",
    "        raise\n",
    "\n",
    "    if iter % print_every == 0:\n",
    "        print('%s (%d %d%%) %.4f' % (timeSince(start), iter, iter / n_iters * 100, loss))\n",
    "\n",
    "    if iter % plot_every == 0:\n",
    "        all_losses.append(total_loss / plot_every)\n",
    "        total_loss = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d8888ad1-d1aa-4c4a-87c9-599930bc7438",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "id": "d8888ad1-d1aa-4c4a-87c9-599930bc7438",
    "outputId": "1ed98845-b4f5-430d-bc07-d4cad1b48bcc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7ffdc1445790>]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(all_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "09559e2c-bb7d-4e14-83bc-1f6abff56af3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "09559e2c-bb7d-4e14-83bc-1f6abff56af3",
    "outputId": "33e3162c-12cc-4b35-b523-f23919254afd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "heart thou the world where the star\n",
      "love the star that thou shall show\n",
      "of the world where the world where the world\n",
      "dear where the world where the world\n",
      "\n",
      "heart thou the world where the\n",
      "be the world where the world\n",
      "just thou the star the world where the star\n",
      "in the world where the world where the\n",
      "\n",
      "heart thou the star that the world where\n",
      "so thou the star what thou mare the world\n",
      "dear where the world where the world where\n",
      "in the world where the world where the world\n",
      "\n",
      "for the world where the world where the\n",
      "where the world where the star that\n"
     ]
    }
   ],
   "source": [
    "# Sample a poem\n",
    "for i in range(14): \n",
    "    original_sample = sample(rnn, random.choice(string.ascii_lowercase[:-3]), \n",
    "                             length=random.randint(30, 50), temperature=0.5)\n",
    "    print(' '.join(original_sample.split(\" \")[:-1]))\n",
    "    if i in [3, 7, 11]:\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "00819690-1893-455e-b4df-84ca8523f160",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "torch.save(rnn.state_dict(), \"./models/lstm_onehot_model_256hdim.pt\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6dea578e-14a6-4cb0-80d4-104d093399a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"shall i compare thee to a summer's day the world where the star what thou mare the world where the world where the world where the world where the world where the world where the world where the world where the world where the world where the world where the world where the world where the world where the world where the world where the world where the world where the world where the world where the world where the world where the world where the world where the world where the world where the world where the world where the world where the world where the world where the world where the world where the world where the world where the world where the world where the world where the world where the world where the world where the world where the world where the world where the world where the world where the world where the world where the world where the world where the world where the world where the world where the star dost thou the starth the starth the world where the world where the star that thou mare the world wher\""
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_sample = sampleMultipleStart(rnn, start_seq=\"shall i compare thee to a summer's day\", \n",
    "                             length=1000, temperature=0.25)\n",
    "\n",
    "start_sample\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "883dbf43-6e5d-40aa-a23f-f48368c25368",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shall i compare thee to a summer's day the world\n",
      "thou mare the world where the world where the world\n",
      "the world where the world where the world where the\n",
      "where the world where the world where the world where\n",
      "world where the world where the world where the world\n",
      "the world where the world where the world where the\n",
      "where the world where the world where the world where\n",
      "world where the world where the world where the world\n",
      "the world where the world where the world where the\n",
      "where the world where the world where the world where\n",
      "world where the world where the world where the world\n",
      "the world where the world where the world where the\n",
      "where the world where the world where the star dost\n",
      "starth the world where the world where the star that\n"
     ]
    }
   ],
   "source": [
    "for line in range(14):\n",
    "    print(' '.join(start_sample.split(\" \")[line * 14:line * 14 + 10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "63c710d3-d8ea-4080-b763-46d179fbeab2",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for RNN:\n\tsize mismatch for lstm.weight_ih_l0: copying a param with shape torch.Size([3200, 30]) from checkpoint, the shape in current model is torch.Size([1024, 30]).\n\tsize mismatch for lstm.weight_hh_l0: copying a param with shape torch.Size([3200, 800]) from checkpoint, the shape in current model is torch.Size([1024, 256]).\n\tsize mismatch for lstm.bias_ih_l0: copying a param with shape torch.Size([3200]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for lstm.bias_hh_l0: copying a param with shape torch.Size([3200]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for decoder.weight: copying a param with shape torch.Size([30, 800]) from checkpoint, the shape in current model is torch.Size([30, 256]).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/2z/n5knmb3s7n9c46lls9ss3vy40000gn/T/ipykernel_33749/2421924448.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# Model class must be defined somewhere\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mrnn_load_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_letters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_letters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mrnn_load_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./models/lstm_onehot_model.pt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mrnn_load_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/bebi/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m   1049\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1050\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1051\u001b[0;31m             raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n\u001b[0m\u001b[1;32m   1052\u001b[0m                                self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n\u001b[1;32m   1053\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_IncompatibleKeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmissing_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munexpected_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for RNN:\n\tsize mismatch for lstm.weight_ih_l0: copying a param with shape torch.Size([3200, 30]) from checkpoint, the shape in current model is torch.Size([1024, 30]).\n\tsize mismatch for lstm.weight_hh_l0: copying a param with shape torch.Size([3200, 800]) from checkpoint, the shape in current model is torch.Size([1024, 256]).\n\tsize mismatch for lstm.bias_ih_l0: copying a param with shape torch.Size([3200]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for lstm.bias_hh_l0: copying a param with shape torch.Size([3200]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for decoder.weight: copying a param with shape torch.Size([30, 800]) from checkpoint, the shape in current model is torch.Size([30, 256])."
     ]
    }
   ],
   "source": [
    "# Load model\n",
    "# Model class must be defined somewhere\n",
    "rnn_load_model = RNN(n_letters, hidden_size, n_letters, device=device, batch_size=batch_size)\n",
    "rnn_load_model.load_state_dict(torch.load(\"./models/lstm_onehot_model.pt\"))\n",
    "rnn_load_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2bf55d5-96eb-4e23-bf37-951e61379dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample a poem\n",
    "for i in range(14): \n",
    "    original_sample = sample(rnn_load_model, random.choice(string.ascii_lowercase[:-3]), \n",
    "                             length=random.randint(30, 50), temperature=3.05)\n",
    "    print(' '.join(original_sample.split(\" \")[:-1]))\n",
    "    if i in [3, 7, 11]:\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "S-eR5T1BlDEI",
   "metadata": {
    "id": "S-eR5T1BlDEI"
   },
   "source": [
    "## Embedding LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "qe9-xqxndmHR",
   "metadata": {
    "id": "qe9-xqxndmHR"
   },
   "outputs": [],
   "source": [
    "class RNN_Embedding(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, n_classes, device, batch_size, n_layers=1): # n_classes is output_size \n",
    "        super(RNN_Embedding, self).__init__()\n",
    "        self.input_size = input_size # input size is number of classes in our case \n",
    "        self.hidden_size = hidden_size # hidden layer size \n",
    "        self.n_classes = n_classes # number of classes \n",
    "        self.batch_size = batch_size # size of batch\n",
    "        self.n_layers = n_layers # number of layers in LSTM\n",
    "        self.device = device # 'cuda' or 'cpu'\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, input_size)\n",
    "        self.lstm = nn.LSTM(input_size=input_size, hidden_size=hidden_size, num_layers=n_layers)\n",
    "        self.decoder = nn.Linear(hidden_size, n_classes)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.softmax = nn.Softmax(dim=2)\n",
    "        \n",
    "\n",
    "    def forward(self, input_vals, hc, temperature=1):\n",
    "        embeding = self.embedding(input_vals)\n",
    "        # pdb.set_trace()\n",
    "        output, hc = self.lstm(embeding, hc)\n",
    "        output = self.decoder(output)\n",
    "        output = self.dropout(output)\n",
    "        # pdb.set_trace()\n",
    "        output = self.softmax(output / temperature)\n",
    "        return output, (hc[0].detach(), hc[1].detach())\n",
    "\n",
    "    def initHidden(self, num_layers=None, batch_size=None, hidden_size=None):\n",
    "        if num_layers is None:\n",
    "            num_layers = self.n_layers\n",
    "        if batch_size is None:\n",
    "            batch_size = self.batch_size\n",
    "        if hidden_size is None:\n",
    "            hidden_size = self.hidden_size\n",
    "            \n",
    "        return torch.zeros(num_layers, batch_size, hidden_size).to(device), torch.zeros(num_layers, batch_size, hidden_size).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "sT4Wij0Udsll",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "sT4Wij0Udsll",
    "outputId": "b9bc93e8-507e-41be-bd31-c0b8d29d28d5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1m 8s (500 3%) 3.8240\n",
      "2m 17s (1000 6%) 3.7995\n",
      "3m 25s (1500 10%) 3.7792\n",
      "4m 33s (2000 13%) 3.7922\n",
      "5m 42s (2500 16%) 3.7556\n",
      "6m 50s (3000 20%) 3.7364\n",
      "7m 58s (3500 23%) 3.7456\n",
      "9m 7s (4000 26%) 3.7432\n",
      "10m 15s (4500 30%) 3.7682\n",
      "11m 24s (5000 33%) 3.7432\n",
      "12m 33s (5500 36%) 3.7413\n",
      "13m 41s (6000 40%) 3.7296\n",
      "14m 49s (6500 43%) 3.7379\n",
      "15m 58s (7000 46%) 3.7264\n",
      "17m 6s (7500 50%) 3.7543\n",
      "18m 14s (8000 53%) 3.7622\n",
      "19m 23s (8500 56%) 3.7134\n",
      "20m 31s (9000 60%) 3.7259\n",
      "21m 40s (9500 63%) 3.7305\n",
      "22m 48s (10000 66%) 3.7294\n",
      "23m 57s (10500 70%) 3.7475\n",
      "25m 5s (11000 73%) 3.7242\n",
      "26m 14s (11500 76%) 3.7074\n",
      "27m 22s (12000 80%) 3.7147\n",
      "28m 31s (12500 83%) 3.7407\n",
      "29m 39s (13000 86%) 3.7130\n",
      "30m 48s (13500 90%) 3.6844\n",
      "31m 56s (14000 93%) 3.6988\n",
      "33m 4s (14500 96%) 3.7126\n",
      "34m 13s (15000 100%) 3.7104\n"
     ]
    }
   ],
   "source": [
    "######### PARAMETERS #########\n",
    "batch_size = 32\n",
    "hidden_size = 256\n",
    "n_iters = 15000\n",
    "print_every = 500\n",
    "plot_every = 500\n",
    "learning_rate = 0.0005\n",
    "############################## \n",
    "\n",
    "rnn_embedding = RNN_Embedding(input_size=n_letters, hidden_size=hidden_size, n_classes=n_letters, n_layers=1, device=device, batch_size=batch_size).to(device) # expand hidden units \n",
    "\n",
    "criterion = nn.CrossEntropyLoss() \n",
    "\n",
    "optimizer = torch.optim.Adam(rnn_embedding.parameters(), lr=learning_rate)\n",
    "\n",
    "import pdb\n",
    "\n",
    "all_losses_embed = []\n",
    "total_loss_embed = 0 # Reset every plot_every iters\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "for iter in range(1, n_iters + 1):\n",
    "    try : \n",
    "        input_line_tensor, target_line_tensor = randomBatch(fixed_length_character_sequences_valid_start, batch_size=batch_size)\n",
    "        loss = train_batch(rnn_embedding, input_line_tensor.to(device), target_line_tensor.to(device), criterion=criterion, optimizer=optimizer)\n",
    "        total_loss_embed += loss\n",
    "    except : \n",
    "        print(input_line_tensor)\n",
    "        raise\n",
    "\n",
    "    if iter % print_every == 0:\n",
    "        print('%s (%d %d%%) %.4f' % (timeSince(start), iter, iter / n_iters * 100, loss))\n",
    "\n",
    "    if iter % plot_every == 0:\n",
    "        all_losses_embed.append(total_loss_embed / plot_every)\n",
    "        total_loss_embed = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ukzPajiGfI7h",
   "metadata": {
    "id": "ukzPajiGfI7h"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7ffdc15409d0>]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(all_losses_embed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "26d81bfb-664c-4a70-8084-81d8f02b077e",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(rnn_embedding.state_dict(), \"./models/lstm_embedding_model_256hdim.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "mqqFvXiEeTQm",
   "metadata": {
    "id": "mqqFvXiEeTQm"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ver so the the state the the star that\n",
      "in the the star the stan the star that the\n",
      "earth the star the star that the star the sterles\n",
      "unthree the stant the star that the star\n",
      "\n",
      "of the seen the stan the tear the star the\n",
      "be the the star the stan the star that the seen\n",
      "be the the star that the star that the\n",
      "goore the sort the the star that the star that\n",
      "\n",
      "euther that the star the star that the star\n",
      "loon another that the stans\n",
      "lool the star the ster that the\n",
      "poor the soul state the that the star that the\n",
      "\n",
      "kin that the stan the stan the state the stare\n",
      "know stans anstate the star\n"
     ]
    }
   ],
   "source": [
    "# Sample a poem\n",
    "for i in range(14): \n",
    "    original_sample = sample(rnn_embedding, random.choice(string.ascii_lowercase[:-3]), \n",
    "                             length=random.randint(30, 50), temperature=3.05)\n",
    "    print(' '.join(original_sample.split(\" \")[:-1]))\n",
    "    if i in [3, 7, 11]:\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9683b447-0550-4a2e-bd7d-d23b7d0eb1aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"shall i compare thee to a summer's day the stant the star that the star that the star that the star that the star that the star that the star that the star that the star that the star that the star that the star that the star that the star that the star the steal the star that the star the steal the stane the star that the star that the star the stan the star that the star that the star that the star that the star that the star the steal the that the star that the star the steal the star that the star that the star that the star that the star the star the stan the star that the star the steal the stant the star that the star that the star the steal the star that the star that the star that the star that the star the steal the star the star the ster that the star that the star that the star the stan the steal the star the stant the star that the star that the star that the star that the star the steal the star that the star the steal the star that the star that the star the steal the stan the star that the star that the sta\""
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_sample = sampleMultipleStart(rnn_embedding, start_seq=\"shall i compare thee to a summer's day\", \n",
    "                             length=1000, temperature=1.5)\n",
    "\n",
    "start_sample\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c875e792-5d73-47d8-9acf-cd39287953c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shall i compare thee to a summer's day the stant\n",
      "star that the star that the star that the star\n",
      "the star that the star that the star that the\n",
      "that the star that the star that the star that\n",
      "the star that the star the steal the stane the\n",
      "that the star the stan the star that the star\n",
      "the star that the star that the star the steal\n",
      "that the star the steal the star that the star\n",
      "the star that the star the star the stan the\n",
      "the steal the stant the star that the star that\n",
      "the star that the star that the star that the\n",
      "the steal the star the star the ster that the\n",
      "that the star the stan the steal the star the\n",
      "the star that the star that the star that the\n"
     ]
    }
   ],
   "source": [
    "for line in range(14):\n",
    "    print(' '.join(start_sample.split(\" \")[line * 14:line * 14 + 10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24280f9f-4462-4323-bbc6-cf939299a985",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "# Model class must be defined somewhere\n",
    "rnn_load_model = RNN_Embedding(n_letters, hidden_size, n_letters, device=device, batch_size=batch_size)\n",
    "rnn_load_model.load_state_dict(torch.load(\"./models/lstm_embedding_model.pt\"))\n",
    "rnn_load_model.eval()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "gc_LSTM_scratch-OneHot.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
