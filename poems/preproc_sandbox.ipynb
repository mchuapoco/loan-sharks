{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "858a5735-8db4-4be9-be5b-a0d3e6cbfab7",
   "metadata": {},
   "source": [
    "# Preprocessing sandbox\n",
    "\n",
    "To help improve our preprocessing script in 'helper.py' use this space to adjust things. This is also helpful for just visulizing what happens at each point in the preprocessing pipeline. \n",
    "\n",
    "Adapted from Miggy and Rahma's work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7eec7180-b53a-44be-a57f-13840fe87b21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'helper' from '/Users/glchau/Desktop/Caltech/CS155/loan-sharks/poems/helper.py'>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import urllib\n",
    "import re\n",
    "import helper\n",
    "\n",
    "# Run this to reload helper.py so you don't have to restart the kernel\n",
    "import importlib\n",
    "\n",
    "importlib.reload(helper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d2e0ea2-52ac-48e4-8718-af57abc1d6fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in syllable dictionary and save outputs into a dictionary\n",
    "\n",
    "with open(\"data/Syllable_dictionary.txt\") as f:\n",
    "    syllable_dict_ = f.readlines()\n",
    "\n",
    "syllable_dict = {}\n",
    "\n",
    "for line in syllable_dict_:\n",
    "    word = line.strip().split()[0]\n",
    "    num = line.strip().split()[-1]\n",
    "    syllable_dict[word] = num\n",
    "    \n",
    "# Create a set of words from the syllable dictionary to match with\n",
    "# words from the sonnet parsing. This is mainly for checking that \n",
    "# our parsing is consistent with the full set of words in syllable_dictionary\n",
    "syllable_words = set(syllable_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a55ba482-6457-456d-bd51-38a7da319516",
   "metadata": {},
   "outputs": [],
   "source": [
    "# they asked us to import directly from github\n",
    "# with urllib.request.urlopen(\"https://github.com/charlesincharge/Caltech-CS155-2022/tree/main/miniprojects/miniproject3/data/shakespeare.txt\") as f:\n",
    "#     shakespeare = f.readlines()\n",
    "with open(\"data/shakespeare.txt\") as f:\n",
    "    shakespeare = f.readlines()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "51a6d23d-fbd2-4ac2-a072-a4bed798fb40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get start line of each sonnet \n",
    "p = re.compile('[\\d]+')\n",
    "start_indexes = []\n",
    "for i, line in enumerate(shakespeare): \n",
    "    if p.match(line.strip()):\n",
    "        start_indexes.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b1e034a7-4611-4f8d-a04c-b5b771161512",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words that are not in intersection with syllable dictionary: set()\n"
     ]
    }
   ],
   "source": [
    "# Parse each sonnet\n",
    "all_words = set()\n",
    "all_sequences = []\n",
    "for start_ind in start_indexes: \n",
    "    # Iterate through each line in the sonnet (starts at index +1 to not use the line that has the number)\n",
    "    for i, line in enumerate(shakespeare[start_ind+1: start_ind+15]): \n",
    "        \n",
    "        # Remove whitespace at start + end of line\n",
    "        clean_line = line.strip()\n",
    "        \n",
    "        # Remove punctuation\n",
    "        clean_line = clean_line.replace(',', '')\n",
    "        clean_line = clean_line.replace(':', '')\n",
    "        clean_line = clean_line.replace('\"', '')\n",
    "        clean_line = clean_line.replace(';', '')\n",
    "        clean_line = clean_line.replace('.', '')\n",
    "        clean_line = clean_line.replace('(', '')\n",
    "        clean_line = clean_line.replace(')', '')\n",
    "        clean_line = clean_line.replace('!', '')\n",
    "        clean_line = clean_line.replace('?', '')\n",
    "        \n",
    "        # Remove capitalization\n",
    "        clean_line = clean_line.lower() \n",
    "        \n",
    "        # Create array of words\n",
    "        clean_words = clean_line.split()\n",
    "        \n",
    "        ## Debating to account for empty lines or not. \n",
    "        ## If we account for empty lines, the resulting number of lines is not evenly divisibly by 14. \n",
    "        # if len(clean_words) == 0 :\n",
    "        #     # If the line is empty as in sonnet 126, continue from this loop early\n",
    "        #     continue \n",
    "        \n",
    "        # Create sequence\n",
    "        sequence = [] \n",
    "        for word in clean_words: \n",
    "            if word not in syllable_words: \n",
    "                # Sometimes words have extra apostrophes at the front and/or end of the word\n",
    "                # that cause it not to appear in the syllable dict. This happens when \n",
    "                # Shakespeare is quoting something like 'I hate' so we can strip the apostrophes\n",
    "                # before adding the word\n",
    "                word = word.strip(\"'\")\n",
    "                \n",
    "            all_words.add(word) \n",
    "            sequence.append(word)\n",
    "            \n",
    "        # Add new-line word to signify end of line.\n",
    "        sequence.append('\\n')  \n",
    "        # TODO: maybe we can have special end-of-line tokens to signify the line #, \n",
    "        # or whether it is part of quatrain or couplet, or is the volta. \n",
    "        \n",
    "        # Add sequence to all sequences\n",
    "        all_sequences.append(sequence)\n",
    "# XOR (i.e. all words not in the intersection of the two sets)\n",
    "# Should be empty set \n",
    "print(\"Words that are not in intersection with syllable dictionary:\", syllable_words ^ all_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8105a850-6002-46d6-8953-2b99d830a82f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word embeddings (assign every word an integer number) \n",
    "word_dict = {} \n",
    "for i, word in enumerate(all_words): \n",
    "    word_dict[word] = i\n",
    "word_dict['\\n'] = i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "19d0446e-25d5-49fb-8fff-a346c378c7ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, convert all_sonnets into integer representation\n",
    "all_sonnet_int = []\n",
    "for sonnet in all_sequences:\n",
    "    current_sonnet = []\n",
    "    for word in sonnet:\n",
    "        current_sonnet.append(word_dict[word])\n",
    "    all_sonnet_int.append(current_sonnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d5097869-b1f8-4325-83a7-88eb3cb6e0f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[2843, 2133, 0, 7, 2400, 2369, 3205],\n",
       " [124, 355, 1837, 1853, 1621, 2109, 477, 3205],\n",
       " [239, 1219, 1757, 1329, 991, 1740, 114, 2918, 3205],\n",
       " [430, 777, 703, 1621, 1971, 430, 1882, 3205],\n",
       " [239, 2313, 1372, 2042, 1886, 129, 440, 2378, 3205],\n",
       " [2137, 1665, 674, 1697, 1780, 2275, 1679, 3205],\n",
       " [1139, 1111, 2449, 2660, 2751, 2254, 3205],\n",
       " [1665, 1048, 1665, 202, 2042, 1665, 95, 1048, 149, 984, 3205],\n",
       " [2313, 124, 2945, 2390, 1757, 130, 1996, 3081, 3205],\n",
       " [3038, 677, 2661, 2042, 1757, 750, 865, 3205]]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_sonnet_int[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3664c50-dc3b-42f2-b572-701eca36dd7c",
   "metadata": {},
   "source": [
    "## Current Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3ed7822e-42f7-41c2-a983-8cf852b0d3c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words, all_sequences, word_dict, all_sonnet_int = helper.getAllWordsAndSequences(\"data/shakespeare.txt\", \"data/Syllable_dictionary.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dbb8455e-063a-4f6f-9753-6337b9322861",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'from fairest creatures we desire increase\\n'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(all_sequences[0][:-1]) + \"\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d7d746-e7bb-42f4-9e13-e6a6149707e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
