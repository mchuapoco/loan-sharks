{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0509ab85-d0db-451e-b894-3017d5c45153",
   "metadata": {},
   "source": [
    "# Train 5 random forests in parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c626914-6b10-4193-a52d-1425a3a6bbf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import roc_auc_score,confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "import copy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fa367c4-86db-41b5-9e39-daeb1c000103",
   "metadata": {},
   "source": [
    "#### Used the best hyperparameters as determined by Geeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d0c652ff-b2f1-49c9-9b94-ca120b8f77b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def standard_scalar_normalize(data_train, data_test): \n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(data_train)\n",
    "    normal_data_train = scaler.transform(data_train)\n",
    "    normal_data_test = scaler.transform(data_test)\n",
    "    return normal_data_train,normal_data_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0fb6afbc-8081-4323-adb0-0d1e6ef11325",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_processed():\n",
    "    '''\n",
    "    Used to read & normalize processed test and train data\n",
    "    '''\n",
    "    data_train=pd.read_csv(\"data/2022-02-07_LOANS_TRAIN.csv\")\n",
    "    data_test=pd.read_csv(\"data/2022-02-07_LOANS_TEST.csv\")\n",
    "    y_train=data_train['loan_status']\n",
    "    data_train.drop(columns=['loan_status', 'id', 'issue_d_in_months', 'issue_d_year', 'zip_state_match'], inplace=True)\n",
    "    \n",
    "    data_test.drop(columns=['id', 'issue_d_in_months', 'issue_d_year', 'zip_state_match'], inplace=True)\n",
    "    \n",
    "    normal_data_train,normal_data_test=standard_scalar_normalize(data_train,data_test)\n",
    "    return normal_data_train,normal_data_test,y_train\n",
    "\n",
    "def AUC_score(y_ground_truth,y_predicted_probability):\n",
    "    return roc_auc_score(y_ground_truth, y_predicted_probability)\n",
    "\n",
    "def to_submission(ids, y_test_predicted_probability):\n",
    "    y_test=pd.DataFrame(y_test_predicted_probability,columns=['loan_status'], index=ids)\n",
    "    y_test.index.name = 'id'\n",
    "    y_test.to_csv('data/submission.csv')\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1ad8086d-dd85-4fb4-8641-a4e9ad223ddd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "X_train shape: (132157, 89)\n",
      "y_train shape: (132157,)\n",
      "X_val shape: (65093, 89)\n",
      "Y_val shape: (65093,)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, Y_train = data_processed()\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size=0.33, random_state=42)\n",
    "\n",
    "print(f\"\"\"\n",
    "X_train shape: {X_train.shape}\n",
    "y_train shape: {Y_train.shape}\n",
    "X_val shape: {X_val.shape}\n",
    "Y_val shape: {Y_val.shape}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54adc26d-30ca-44cf-aa4c-01f59794dc5f",
   "metadata": {},
   "source": [
    "### I'll shuffle the training data, then split it into 5 data sets (since there is ~5x as many data points for the majority class (Paid Off) than the minority classs (Charged Off)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "43b65530-53a4-4f3d-880b-bb824bcbbce4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 111917 training examples for class 0 and 20240 training examples for class 1.\n",
      "There is approx 5.53 times as many examples for class 0 than class 1.\n"
     ]
    }
   ],
   "source": [
    "count_0 = np.count_nonzero(Y_train == 0)\n",
    "count_1 = np.count_nonzero(Y_train == 1)\n",
    "\n",
    "factor = count_0/count_1\n",
    "\n",
    "print(f\"There are {count_0} training examples for class 0 and {count_1} training examples for class 1.\")\n",
    "print(f\"There is approx {factor:.2f} times as many examples for class 0 than class 1.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "517284ef-aa22-435e-9210-1da040003b18",
   "metadata": {},
   "source": [
    "For now, I'll just do 5 models and ignore the last 0.53 part of the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0265e7cd-6430-4517-8c77-53b807038292",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "class 0 : (111917, 89)\n",
      "class 1 : (20240, 89)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# separate all the class 0 from the class 1 examples\n",
    "\n",
    "indices_0 = np.where(Y_train == 0)\n",
    "indices_1 = np.where(Y_train == 1)\n",
    "\n",
    "training_0 = X_train[indices_0, :][0]\n",
    "training_1 = X_train[indices_1, :][0]\n",
    "\n",
    "print(f\"\"\"\n",
    "class 0 : {training_0.shape}\n",
    "class 1 : {training_1.shape}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21d1d1f8-9a15-41d9-81a4-d46f2134989e",
   "metadata": {},
   "source": [
    "Now that I've split the class 0 and class 1, I'm going to create 5 balanced datasets for each of the random forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1b50dc43-ae8b-4aab-8121-038721e26921",
   "metadata": {},
   "outputs": [],
   "source": [
    "def balance_dataset(start_index, class_0_examples, class_1_examples):\n",
    "    end = start_index + 20240\n",
    "    \n",
    "    training_0_1 = class_0_examples[start_index:end, :]\n",
    "\n",
    "    # combine and shuffle, with the training labels!\n",
    "    new_x_train = np.concatenate((training_0_1, class_1_examples))\n",
    "    new_y_train = np.concatenate((np.zeros(20240), np.ones(20240)))\n",
    "    \n",
    "    print(f\"x_train shape: {new_x_train.shape} and y_train shape: {new_y_train.shape}\")\n",
    "\n",
    "    new_x_train, new_y_train = shuffle(new_x_train, new_y_train, random_state=0)\n",
    "    \n",
    "    return new_x_train, new_y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7bdb3cf7-ec07-4baf-bebe-6f03a70170ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([     0,  20240,  40480,  60720,  80960, 101200])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.arange(0, 111917, 20240) #these are the starting indicies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "43363bef-d363-4567-b360-d554e0ba0742",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (40480, 89) and y_train shape: (40480,)\n",
      "x_train shape: (40480, 89) and y_train shape: (40480,)\n",
      "x_train shape: (40480, 89) and y_train shape: (40480,)\n",
      "x_train shape: (40480, 89) and y_train shape: (40480,)\n",
      "x_train shape: (40480, 89) and y_train shape: (40480,)\n"
     ]
    }
   ],
   "source": [
    "X_train_1, Y_train_1 = balance_dataset(0, training_0, training_1)\n",
    "X_train_2, Y_train_2 = balance_dataset(20240, training_0, training_1)\n",
    "X_train_3, Y_train_3 = balance_dataset(40480, training_0, training_1)\n",
    "X_train_4, Y_train_4 = balance_dataset(60720, training_0, training_1)\n",
    "X_train_5, Y_train_5 = balance_dataset(80960, training_0, training_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9b958bf-3706-473d-802a-291f5899afe1",
   "metadata": {},
   "source": [
    "I also want to try adding a 6th model that will be inbalanced in favor of the minority class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9e154324-57eb-4ea6-9c6c-475bafdeb96b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # split all into train and validation\n",
    "# X_train_1, X_val_1, Y_train_1, Y_val_1 = train_test_split(X_train_1, Y_train_1, train_size=0.33, random_state=42)\n",
    "# X_train_2, X_val_2, Y_train_2, Y_val_2 = train_test_split(X_train_2, Y_train_2, train_size=0.33, random_state=42)\n",
    "# X_train_3, X_val_3, Y_train_3, Y_val_3 = train_test_split(X_train_3, Y_train_3, train_size=0.33, random_state=42)\n",
    "# X_train_4, X_val_4, Y_train_4, Y_val_4 = train_test_split(X_train_4, Y_train_4, train_size=0.33, random_state=42)\n",
    "# X_train_5, X_val_5, Y_train_5, Y_val_5 = train_test_split(X_train_5, Y_train_5, train_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61c535a2-2240-4d1e-92b6-8490ccc48909",
   "metadata": {},
   "source": [
    "#### Random Forest #1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e8910678-2f28-4978-826f-937333e7b879",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.685744850037292"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc = RandomForestClassifier(class_weight='balanced', max_depth=20, min_samples_leaf=25, n_estimators=400)\n",
    "rfc.fit(X_train_1, Y_train_1)\n",
    "Y_train_pred_prob_1 = rfc.predict_proba(X_val)[:,1]\n",
    "AUC_score(Y_val, Y_train_pred_prob_1) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fda98d5-8e14-441b-b95d-c8501ba8a9ba",
   "metadata": {},
   "source": [
    "#### Random Forest #2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "72650d81-1d78-47a8-bf23-f8207568810c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6859965747224266"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc = RandomForestClassifier(class_weight='balanced', max_depth=20, min_samples_leaf=25, n_estimators=400)\n",
    "rfc.fit(X_train_2, Y_train_2)\n",
    "Y_train_pred_prob_2 = rfc.predict_proba(X_val)[:,1]\n",
    "AUC_score(Y_val, Y_train_pred_prob_2) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bee30d2-3223-432f-86a8-88040c344363",
   "metadata": {},
   "source": [
    "#### Random Forest #3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5dbe1162-235c-4c40-ad26-a816b365fb42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6857901419785312"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc = RandomForestClassifier(max_depth=20, min_samples_leaf=25, n_estimators=400)\n",
    "rfc.fit(X_train_3, Y_train_3)\n",
    "Y_train_pred_prob_3 = rfc.predict_proba(X_val)[:,1]\n",
    "AUC_score(Y_val, Y_train_pred_prob_3) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14eb6f47-d247-4e74-aa06-08feb0a8e6d6",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Random Forest #4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "680d8612-c63e-4b7f-b389-ad2c2cf00e5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6862713997515879"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc = RandomForestClassifier(class_weight={0:5, 1:1}, max_depth=20, min_samples_leaf=25, n_estimators=400)\n",
    "rfc.fit(X_train_4, Y_train_4)\n",
    "Y_train_pred_prob_4 = rfc.predict_proba(X_val)[:,1]\n",
    "AUC_score(Y_val, Y_train_pred_prob_4) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e6c928b-8912-418e-9c8d-1719af58f4b5",
   "metadata": {},
   "source": [
    "#### Random Forest #5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "59ce3c40-c714-42d4-8e3b-6eb955431808",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6866429154418214"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc = RandomForestClassifier(class_weight={0:1, 1:5}, max_depth=20, min_samples_leaf=25, n_estimators=400)\n",
    "rfc.fit(X_train_5, Y_train_5)\n",
    "Y_train_pred_prob_5 = rfc.predict_proba(X_val)[:,1]\n",
    "AUC_score(Y_val, Y_train_pred_prob_5) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73706fe5-fa51-421b-b1a1-b854f1eb2d97",
   "metadata": {},
   "source": [
    "### Now, combine the outputs of all the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4a91814e-480a-4147-97dc-c18080ba8313",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6871708010139346"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# try averaging probability\n",
    "all_pred_prob = np.vstack((Y_train_pred_prob_1, \n",
    "                           Y_train_pred_prob_2,\n",
    "                           Y_train_pred_prob_3, \n",
    "                           Y_train_pred_prob_4,\n",
    "                           Y_train_pred_prob_5))\n",
    "\n",
    "avg_pred = np.mean(all_pred_prob, axis=0)\n",
    "\n",
    "# avg_pred[avg_pred > 0.5] = 1\n",
    "# avg_pred[avg_pred <= 0.5] = 0\n",
    "\n",
    "AUC_score(Y_val, avg_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "94de3ece-a016-4bd0-a68f-8d7e011726df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6874262533785025"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# try feeding in the probabilities as features to a logistic regression model\n",
    "X_blend = np.hstack((Y_train_pred_prob_1.reshape(-1,1), \n",
    "                     Y_train_pred_prob_2.reshape(-1,1),\n",
    "                     Y_train_pred_prob_3.reshape(-1,1), \n",
    "                     Y_train_pred_prob_4.reshape(-1,1),\n",
    "                     Y_train_pred_prob_5.reshape(-1,1)))\n",
    "\n",
    "clf = LogisticRegression(random_state=0, max_iter=1000)\n",
    "clf.fit(X_blend, Y_val)\n",
    "Y_val_pred_prob = clf.predict_proba(X_blend)[:,1]\n",
    "roc_auc_score(Y_val, Y_val_pred_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cd6215f-fdec-458c-8cdc-ef62b308a4ce",
   "metadata": {},
   "source": [
    "## Now, try a sequential ensemble model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7ed3d27b-4c3d-4262-b08c-154e9d42f9c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc0 = RandomForestClassifier(class_weight='balanced', max_depth=20, min_samples_leaf=25, n_estimators=400)\n",
    "rfc0.fit(X_train, Y_train)\n",
    "Y_train_pred_prob = rfc0.predict_proba(X_train)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ebd81a34-a90d-483f-9666-195ac765839d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "X has 89 features, but RandomForestClassifier is expecting 1 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/h7/dxctt03x2vjdfbhcmgymr3400000gn/T/ipykernel_14710/2069328651.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mrfc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'balanced'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_depth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_samples_leaf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_estimators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m400\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mrfc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_train_pred_prob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mY_train_pred_prob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrfc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    848\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    849\u001b[0m         \u001b[0;31m# Check data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 850\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    851\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    852\u001b[0m         \u001b[0;31m# Assign chunk of trees to jobs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36m_validate_X_predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    577\u001b[0m         Validate X whenever one tries to predict, apply, predict_proba.\"\"\"\n\u001b[1;32m    578\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 579\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDTYPE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"csr\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    580\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0missparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintc\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindptr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"No support for np.int64 index based sparse matrices\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    583\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    584\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcheck_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ensure_2d\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 585\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_n_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    586\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_check_n_features\u001b[0;34m(self, X, reset)\u001b[0m\n\u001b[1;32m    398\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    399\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_features\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_features_in_\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 400\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    401\u001b[0m                 \u001b[0;34mf\"X has {n_features} features, but {self.__class__.__name__} \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m                 \u001b[0;34mf\"is expecting {self.n_features_in_} features as input.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: X has 89 features, but RandomForestClassifier is expecting 1 features as input."
     ]
    }
   ],
   "source": [
    "rfc = RandomForestClassifier(class_weight='balanced', max_depth=20, min_samples_leaf=25, n_estimators=400)\n",
    "rfc.fit(Y_train_pred_prob.reshape(-1, 1), Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fe4c7504-6e74-4d6a-bbae-064814a4a573",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train_pred_prob = rfc.predict_proba(rfc0.predict_proba(X_train)[:,1].reshape(-1, 1))[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4db81bb0-91b5-4fa7-a453-257a8676e178",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier(class_weight='balanced', max_depth=20, min_samples_leaf=25, n_estimators=400)\n",
    "rfc.fit(Y_train_pred_prob.reshape(-1, 1), Y_train)\n",
    "Y_train_pred_prob = rfc.predict_proba(rfc0.predict_proba(X_train)[:,1].reshape(-1, 1))[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "68c69864-af39-4556-9519-0594125b65a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier(class_weight='balanced', max_depth=20, min_samples_leaf=25, n_estimators=400)\n",
    "rfc.fit(Y_train_pred_prob.reshape(-1, 1), Y_train)\n",
    "Y_train_pred_prob = rfc.predict_proba(rfc0.predict_proba(X_train)[:,1].reshape(-1, 1))[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f66f0abf-d382-4294-8b5e-877776ba5b7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(class_weight='balanced', max_depth=20,\n",
       "                       min_samples_leaf=25, n_estimators=400)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc = RandomForestClassifier(class_weight='balanced', max_depth=20, min_samples_leaf=25, n_estimators=400)\n",
    "rfc.fit(Y_train_pred_prob.reshape(-1, 1), Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "66a32a82-8fe9-4476-b1d6-dd0dcc78579d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "X has 89 features, but RandomForestClassifier is expecting 1 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/h7/dxctt03x2vjdfbhcmgymr3400000gn/T/ipykernel_14710/1529640455.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mY_val_pred_prob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrfc0\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mY_val_pred_prob_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrfc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    848\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    849\u001b[0m         \u001b[0;31m# Check data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 850\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    851\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    852\u001b[0m         \u001b[0;31m# Assign chunk of trees to jobs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36m_validate_X_predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    577\u001b[0m         Validate X whenever one tries to predict, apply, predict_proba.\"\"\"\n\u001b[1;32m    578\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 579\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDTYPE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"csr\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    580\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0missparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintc\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindptr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"No support for np.int64 index based sparse matrices\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    583\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    584\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcheck_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ensure_2d\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 585\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_n_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    586\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_check_n_features\u001b[0;34m(self, X, reset)\u001b[0m\n\u001b[1;32m    398\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    399\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_features\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_features_in_\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 400\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    401\u001b[0m                 \u001b[0;34mf\"X has {n_features} features, but {self.__class__.__name__} \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m                 \u001b[0;34mf\"is expecting {self.n_features_in_} features as input.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: X has 89 features, but RandomForestClassifier is expecting 1 features as input."
     ]
    }
   ],
   "source": [
    "Y_val_pred_prob = rfc0.predict_proba(X_val)[:,1]\n",
    "Y_val_pred_prob_ = rfc.predict_proba(X_val)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b4a02f-4bf0-4099-aa0e-52f3128d38e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "conf = confusion_matrix(y_val, prediction, normalize='true')\n",
    "disp = ConfusionMatrixDisplay(conf)\n",
    "disp.plot()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
